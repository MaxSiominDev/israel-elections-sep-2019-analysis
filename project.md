# Анализ результатов выборов в Кнессет с использованием методов машинного обучения

## Описание задачи

В рамках проекта решается задача предсказания партии-победителя на избирательных участках на основе их характеристик. Используются данные реальных выборов в Кнессет (сентябрь 2019 года)

Основная цель - построить модель классификации, которая может предсказать, какая партия получит наибольшее количество голосов на конкретном участке, опираясь на демографические и социально-экономические признаки

## Датасет

### Общее описание

Датасет содержит результаты выборов в Кнессет в сентябре 2019 года, разбитые по отдельным избирательным участкам. Это реальные данные, каждая строка представляет собой отдельный участок для голосования

В датасете присутствуют данные о голосовании за основные политические партии Израиля

### Проблемы в данных

Как и в любом реальном датасете, есть проблемы с заполненностью некоторых признаков:

- `stat2011` - заполнено примерно на 74%
- `yishuv_stat2011` - заполнено на 84%
- `socio_econ_cluster_2015` - заполнено на 79%

Названия населённых пунктов представляют собой категориальные данные с большим количеством уникальных значений (что создаёт трудности для моделей)

Некоторые признаки содержат выбросы, но это реальные данные - например, крупные города с большим количеством избирателей или маленькие поселения

## Архитектура проекта

Проект разделён на несколько модулей для удобства и переиспользования кода:

### Основные модули

**`hebrew.py`**  
Содержит маппинги для перевода названий колонок с иврита на английский, списки партий и населённых пунктов. Занимается первичной обработкой названий

**`party.py`**  
Определяет классы партий и их идеологическую принадлежность (левые, центр, правые). Это позволяет анализировать результаты не только по отдельным партиям, но и по идеологическим блокам

**`arabic.py`**  
Интересный модуль для определения арабских населённых пунктов. Использует два подхода:
- Rule-based: поиск характерных паттернов в названиях (umm, abu, kafr, etc.)
- ML-based: обучение LogisticRegression на символьных n-граммах (2-4 символа)

Оба подхода комбинируются - сначала проверяются правила, если не сработало, то используется модель. Точность получилась довольно высокая, потому что у арабских названий есть явные лингвистические особенности

**`feature.py`**  
Определяет структуру признаков - какие из них числовые, какие категориальные. Это используется дальше в пайплайнах обработки

Используемые признаки для обучения:
- `concentration` (категориальный)
- `socio_econ_cluster_2015` (категориальный)
- `is_arabic_settlement` (категориальный)
- `voters` (числовой)
- `valid_votes` (числовой)
- `valid_share` (числовой)

**`prepare_df.py`**  
Главный модуль предобработки данных:
1. Загружает CSV с результатами
2. Удаляет ненужные колонки
3. Переводит названия на английский
4. Создаёт признак `is_arabic_settlement`
5. Группирует мелкие партии в категорию "Other Parties"
6. Вычисляет `valid_share` - долю действительных голосов
7. Сортирует партии по общему количеству полученных голосов
8. Создаёт целевую переменную `winner_party` - партия с максимальным количеством голосов на участке

**`visualize.py`**  
Модуль для визуализации данных. Включает:
- Распределение количества избирателей по участкам
- Распределение социально-экономических кластеров
- Визуализацию голосования по партиям в разрезе признаков
- Визуализацию по идеологиям (левые/центр/правые)

Это помогло понять, что социально-экономические кластеры сильно влияют на предпочтения избирателей

**`ai.py`**  
Основной модуль машинного обучения. Включает:
- Пайплайн предобработки (StandardScaler для числовых признаков, OneHotEncoder для категориальных)
- Функцию обучения и предсказания
- Расчёт weighted random accuracy (базовая метрика)
- Анализ влияния признаков на качество предсказания

Тестируются 4 классические модели:
- Random Forest
- Logistic Regression
- K-Nearest Neighbors
- Gradient Boosting

**`nn.py`**  
Модуль с нейронной сетью. Архитектура довольно простая:
- Входной слой (размерность зависит от количества признаков после one-hot encoding)
- Dense(128) + ReLU + Dropout(0.3)
- Dense(64) + ReLU
- Dense(количество классов) + Softmax

Обучается 200 эпох с batch_size=32. Использует категориальную кросс-энтропию как функцию потерь

## Предобработка данных

### Обработка пропущенных значений

С пропусками решил не делать ничего радикального - они остались как есть (NaN). Дело в том, что:
1. Для категориальных признаков OneHotEncoder умеет работать с пропусками
2. Удаление строк привело бы к потере ~20-25% данных
3. Заполнение средними/модами может внести искажения

Единственное, что сделал - это создал искусственный признак `has_cluster` для анализа (есть ли значение socio_econ_cluster_2015 или нет)

### Feature Engineering

Самая интересная часть - создание новых признаков:

**1. valid_share**  
Доля действительных голосов = valid_votes / (valid_votes + invalid_votes)  
Этот признак показывает "качество" голосования - где избиратели внимательнее заполняли бюллетени

**2. is_arabic_settlement**  
Бинарный признак, определяющий арабское поселение. Оказалось очень важным - в арабских поселениях паттерны голосования сильно отличаются. Например, в таких поселениях доминирует Объединённый список (Joint List)

Для определения использовал комбинацию правил и ML:
- Правила ловят очевидные случаи (Umm al-Fahm, Kafr Qasim и т.д.)
- Логистическая регрессия на символьных n-граммах ловит менее очевидные

**3. Группировка мелких партий**  
Партии, набравшие мало голосов, сгруппированы в "Other Parties". Это уменьшило размерность задачи и убрало шум

### Кодирование признаков

Использовал `ColumnTransformer` из sklearn:
- Числовые признаки (`voters`, `valid_votes`, `valid_share`) - StandardScaler
- Категориальные (`concentration`, `socio_econ_cluster_2015`, `is_arabic_settlement`) - OneHotEncoder

OneHotEncoder настроен с `handle_unknown='ignore'`, чтобы не падать на новых категориях (хотя на тестовой выборке такого быть не должно)

### Разделение данных

Train/test split - 80/20 с `random_state=69` для воспроизводимости результатов

## Машинное обучение

### Выбор моделей

Решил попробовать разные подходы:

1. **Random Forest** - ансамбль деревьев, хорошо работает с категориальными признаками
2. **Logistic Regression** - простая линейная модель, хорошая базовая линия
3. **K-Nearest Neighbors** - метод k ближайших соседей, хорош для локальных паттернов
4. **Gradient Boosting** - бустинг, часто даёт лучшее качество
5. **Neural Network** - для эксперимента добавил нейронку

### Метрики

Основная метрика - **accuracy** (доля правильных ответов). Это логично для задачи многоклассовой классификации

Также считаю **weighted random accuracy** - точность случайного классификатора, который предсказывает классы с вероятностями, пропорциональными их частоте в обучающей выборке. Это помогает понять, насколько модель лучше простого угадывания

### Результаты

Примерные результаты моделей (на тестовой выборке):

**Random Forest (n_estimators=100)**
- Accuracy: ~0.71

Эксперименты с количеством деревьев показали:
- n_estimators=3: 0.65
- n_estimators=100: 0.711
- n_estimators=1000: 0.719
- n_estimators=5000: 0.718

После 100 деревьев улучшение минимальное, так что остановился на этом значении

**Logistic Regression**
- Accuracy: ~0.65-0.68

Линейная модель работает хуже - видимо, зависимости нелинейные

**K-Nearest Neighbors (k=5)**
- Accuracy: ~0.60-0.63

KNN показал себя хуже всего. Возможно, проблема в том, что после one-hot encoding размерность выросла, и "близость" в таком пространстве работает плохо

**Gradient Boosting (n_estimators=100)**
- Accuracy: ~0.72-0.73

Лучший результат среди классических моделей

**Neural Network**
- Accuracy: ~0.70-0.73

Нейронка показала результаты сравнимые с Random Forest. Возможно, с тюнингом гиперпараметров можно было бы выжать больше, но для небольшого датасета разница не критична

**Weighted Random Accuracy**: ~0.15-0.20

Все модели значительно лучше случайного угадывания, что хорошо

### Анализ влияния признаков

Интересное наблюдение - наличие признака `socio_econ_cluster_2015` влияет на качество предсказания:

Когда у участка есть информация о социально-экономическом кластере, точность предсказания выше на 20-25%. Это говорит о том, что этот признак действительно важен

### Эксперимент с settlement_name

Попробовал добавить `settlement_name` как признак - accuracy подскочила до **0.80**!

Это логично - в каждом населённом пункте есть устойчивые паттерны голосования. Но это немного "читерство", потому что модель по сути запоминает, как голосует каждый город. В реальной жизни такая модель не будет обобщаться на новые поселения

Поэтому для финальной версии оставил модель без `settlement_name` - она более честная и обобщающаяся

## Выводы

### Что получилось хорошо

1. **Данные**  
   Реальный датасет с выборов - это интересно работать с настоящими данными, а не синтетикой

2. **Feature engineering**  
   Признак `is_arabic_settlement` оказался очень полезным. Автоматическое определение через ML работает хорошо

3. **Модели**  
   Gradient Boosting показал лучшее качество среди не-нейронок (~0.73 accuracy), что в целом неплохо для задачи с 11 классами

4. **Архитектура**  
   Разделение кода на модули сделало проект чистым и понятным

### Что можно улучшить

1. **Обработка пропусков**  
   Можно попробовать разные стратегии заполнения (медианой, модой, предсказанием через другую модель)

2. **Feature engineering**  
   - Можно добавить признаки взаимодействия (например, `voters * valid_share`)
   - Можно использовать географические данные (координаты)
   - Можно добавить исторические данные предыдущих выборов

3. **Гиперпараметры**  
   Не делал подробный grid search, только базовую настройку. GridSearchCV или RandomizedSearchCV могли бы улучшить результаты

4. **Балансировка классов**  
   Некоторые партии встречаются реже - можно попробовать SMOTE или взвешивание классов

5. **Нейронная сеть**  
   Архитектура довольно простая. Можно попробовать:
   - Больше слоёв
   - Batch normalization
   - Разные функции активации
   - Регуляризация (L1/L2)

6. **Ансамбли**  
   Можно попробовать stacking - комбинировать предсказания разных моделей

### Основные инсайты

1. **Социально-экономический статус важен**  
   Признак `socio_econ_cluster_2015` сильно влияет на паттерны голосования

2. **Этническая принадлежность играет роль**  
   В арабских поселениях совершенно другие паттерны голосования (доминирует Joint List)

3. **Размер участка имеет значение**  
   Количество избирателей коррелирует с типом поселения и, соответственно, с предпочтениями

### Итог

В целом проект получился неплохим. Удалось построить модель, которая предсказывает победившую партию на участке с точностью около 73%, что значительно лучше случайного угадывания. Код структурирован, используются современные подходы к обработке данных

В реальной жизни такая модель могла бы использоваться для анализа электоральных трендов или оптимизации предвыборных кампаний